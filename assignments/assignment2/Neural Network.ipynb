{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# print(\"LINE 1 CHECKED\")\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "# print(\"LINE 2 CHECKED\")\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')\n",
    "# print(\"LINE 3 CHECKED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3015411189794577\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "# print(loss_with_reg)\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302334, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302729, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301429, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301913, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301518, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303550, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301600, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303765, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301821, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302805, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302877, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301806, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301712, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301950, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302079, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302755, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301758, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12d5e1d60>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtmElEQVR4nO3dfZBk11nf8e/Tb9PTPdPdM9OzO7Na2ZJsmbCAscVKxgYEBsdIhJIwkUECCguoUggoCUURSlUkwiWKqoALQpEoRCJxBSj8BuFFSeRICnHiJNigtSzLXglba1nW7mpmd157Zvplerr75I97e7Z3dl5uT9/unun5faqmpl9u33u299xnznnuOeeacw4RERlckX4XQEREukuBXkRkwCnQi4gMOAV6EZEBp0AvIjLgYv0uwFb5fN7dcMMN/S6GiMih8rnPfW7eOTe53XsHLtDfcMMNnDlzpt/FEBE5VMzs6zu9p9SNiMiAU6AXERlwCvQiIgNOgV5EZMAp0IuIDDgFehGRAadALyIy4A7cOPp9qxbh//5OZ/uIxODb7ofR42GUqH3PfwQWv9afY0s4vvkfwrG/159jv/wMnP/b/hxbwpE5Aad/KvTdDk6g3yjDpz/UwQ78dfnjw/Ad/zSUIrVlfQ3+4h/7T6z3x5cQOChcgPf9Xn8O/99+EZZfQ/XnEDt5WoF+V+k8fHB5/593Dn59CopzoRWpLc3j3v3v4O0/3p8ySGce/57+1R+AtTl454Pw/b/evzLIgaQcfZMZpCagtNCf4zePm5roz/Glc6kJKM3359jVItTKqj+yLQX6VqkJKPbpRG0eN53vz/Glc6k8FPvUUFD9kV0o0LdK59Wil/07EPVHgV6upUDfKpXvX9e7pBbZoZeagI2iNzCg15qBXvVHtqFA3yo10d+udzQBiZH+HF861+yN9SP91zymeoSyDQX6VukJqK5Cbb33xy4teD0K09C4Q6vZmu5Hr7CkQC87U6Bv1cxv9iPPWlrw/tDI4dXv+hOJQzLb+2PLgadA36rZIutX11sX0g63zfrTh0BfnPda8+oRyjYU6Fs1u7396nqr2324pca9332pPwuqP7IjBfpWqX62yBY0YuKwS+a89ZL61SNU6k92oEDfKt2nHGtt3bsIrNTN4dbP2dXNi/ki21Cgb5XMgUV63/XeHAOtFtmhl+rTpKnSvHqEsiMF+laRCAyP977rrTHQgyPVh/pT34BKQfVHdhQo0JvZHWb2ZTM7Z2YPbfP+L5rZi2b2gpn9lZm9seW9D5jZy/7PB8IsfFek+zA7dnMMtFpkh15f6o+Wz5Dd7RnozSwKPArcCZwC7jOzU1s2+zxw2jn3VuBPgd/0PzsO/CrwDuA24FfNbCy84ndBKg+lxd4es3k8db0Pv36kbrT8gewhSIv+NuCcc+4V51wV+Bhwd+sGzrlPOedK/tPPAif9x98PPOOcW3TOLQHPAHeEU/QuSfdhBcuiWvQDI52H8hLUa707puqP7CFIoL8OON/y/IL/2k5+BvhkO581swfM7IyZnZmb6+ONG6A/a4qX5gGD4Vxvjyvha6ZPyj3sFWr5A9lDqBdjzewngNNAW/f0c8497pw77Zw7PTk5GWaR2tdM3TTqvTtmcd67iBeJ9u6Y0h39WNisqNSN7C5IoL8IXN/y/KT/2lXM7D3ArwB3OefW2/nsgZLOAw7Ky707psZAD45+zMVoHmt4vHfHlEMlSKB/FrjZzG40swRwL/BE6wZm9nbgMbwgf7nlraeA95rZmH8R9r3+awdXP5ZBKGlW7MDYXNisl/VnHobHIDo4t4CWcO0Z6J1zNeBBvAD9EvAJ59xZM3vEzO7yN/sQMAL8iZk9b2ZP+J9dBH4N74/Fs8Aj/msHV1+63vNX1kmRw61v9Uf5edlZoCaAc+5J4Mktrz3c8vg9u3z2w8CH91vAnuvHmuKleUi9q3fHk+7ZXNisx6kbpf5kF5oZu1Wv1xRv1L3heErdDIZo3FtKo9eBXvVHdqFAv1WzRdarFSzLy+AaapENknReqRs5UBTot4oNwVCmd6kbjYEePL2ci9FoaC162dPAXKYvrtf41898paN9RKPG/e+6gelUD2fHtqxc+UefeZWvL5R2314OtPfdch3flMrD0qu9OeB6AVwd0nn++5dmOPPqUm+OK11xIjfMT3/njaHvd2AC/XqtwUf/9rWO9lGs1skk4/x8uofrlfh/UFYjOf7lX54lEY0Qj+p2cIdRaaPO5dV1fjc9ARc/15uDNlOMqTwffOJF5tfWGYqpo35YvfVkToF+N+PpBGcf6WwZnbc98jQzhbLXDV7p0bwuv4t/qZ4G4Ld/9Fv5wbee6M2xJVQ/8thnmC1UYNJvKDjX/Xu4+vWnNjzOpdUK/+Tdb+YX3/sN3T2mHDr6099iKpP0TtRUvncXY/3jXKimAJjOJntzXAnddDbJzIrfUGj4a8R3m98jXHKjOAdT2eHuH1MOHQX6FtPZJDOFireCZWnea5F1W2kBEqPMrHnH0ol6eE1lk1wqrNPYnF3dg8aCf4yZ2gighoJsT4G+xXRu2Av0qTzUq1Bd6/5BS95NnWeWy0QMjo0Odf+Y0hUnssNU6w1WIjnvhZ4Eeq9Fv9kjzCnQy7UU6FtMZ5IsFqtsDPn3RunFyJviPKTyzBQqTI4OEY/qv+SwmvJb03MNr3Xdm/qzAPE0r/ttkumMeoRyLUWVFs0TdYmM90KvWmSpCWZXKkrbHHLNtMmM37ruyVh6v/7MFCoMx6NkhgdmfIWESIG+xYmcF2gvNUa9F3rRIistQtpr0Z9QfvVQm/b/UJ9vBvqe1J8FSE8wW6gwnUti3R7lI4eSAn2LZov+9c0WWZdb9M5BcR6X8nL0Uwr0h9pEOkE8apxfNYinetMj9FN/rxfKuhArO1KgbzGV8U6U1yp+CqXbXe/qGtTXWR8ao1it60Q95CIR43gmyWyh3LubhPsLms0WKkwpPy87UKBvkR6KkUnGOL8WgehQ97ve/v6X/WsCytEffptDdFPjPbuY3xge5/LquhoKsiMF+i1O5IaZWVn3ViDsdous5N2DZc6/JqAc/eE3nR1mdqXi159u9whLUCtTjOaoN5yGVsqOFOi3mMomryyD0PVA7wWCmY305rHlcGu26F0P68+iZTaPLbIdBfotprPNZRB6sIKlv/8L6ynM4NioTtTDbiqbpFprUImPdX8ZDb/+zNW9HqFy9LITBfotpjLDzK9VqQ/3YE1xf/+vlobJjwyR0KqDh16zVV2IZGCjCBvl7h2sufzBhtZJkt0psmzRzHMWY7nut8hKCxBN8LVVU35+QDTH0i86f9JdN3uFfqB/rZIiGY+QS8W7dyw51BTot9hskVkWqqtQW+/ewYreTZ1nV9aVnx8Qzfpzqe4vg9DNPL3/R+Rr5WGms8OaLCU7ChTozewOM/uymZ0zs4e2ef92M3vOzGpmds+W937DzL7k//xoWAXvluaJuuB6cKL6C5rNFiqbLUE53CZGhohFjItV7wJ7V9N/pXmIxPjaanRzDojIdvYM9GYWBR4F7gROAfeZ2aktm70G3A98ZMtn/wFwC/A24B3AL5n5QwQOqOZY9s0WWTe73sV5aslxVtdratEPiKg/aep82f/D3c30X7G5TpLG0MvugrTobwPOOedecc5VgY8Bd7du4Jx71Tn3AtDY8tlTwKedczXnXBF4AejsNlBdNjIUYzQZ48J6DxamKi1QjuUAXUgbJNPZJOdK/nLTXa0/izh/QTyNoZfdBAn01wHnW55f8F8L4gvAHWaWMrM88G7g+q0bmdkDZnbGzM7Mzc0F3HX3TGeTfL3cDPSL3TtQaWFz7XKlbgbHVDbJV1diEIl1PfVXHRqn3nCaVS276urFWOfc08CTwF8DHwU+A9S32e5x59xp59zpycnJbhYpkKnsMF9ttsi6lbqprcP6Cotossug8W4puO5Nmupy6q8U8+6dMK0cvewiSKC/yNWt8JP+a4E4537dOfc259zfBwz4SntF7L3pTJKXV+Jgke51vf2W3px/U/BjGd1ZalBMZYdZrzVoJMe73qJfifiTpdRQkF0ECfTPAjeb2Y1mlgDuBZ4IsnMzi5rZhP/4rcBbgaf3W9hemc4lmStu4Ia7uDCVHwBe30iTHxliKBbtznGk55pzIsqJse7Vn7p38/EFf7x+814KItvZM9A752rAg8BTwEvAJ5xzZ83sETO7C8DMbjWzC8D7gcfM7Kz/8Tjwf8zsReBx4Cf8/R1o09kkzkGtmy0yPwC8VkkpbTNgmq3rYjTbvfrjXzu6XB8hEYswpslSsotA9x1zzj2Jl2tvfe3hlsfP4qV0tn6ugjfy5lBpXtgqx3PEu3aievt9pTTM1DEF+kHSvLC+bFmOdy315+334sYI01ndWUp2p5mx22h2vdeiue51vf39vryW0PIHA2ZydIhoxFhojEB5Cepd6MT69ed8OakeoexJgX4bV90kvIsXYx3G+UpSQ+MGTDRiHB8dYqbmT7ord2GIrt8jPFdMamiu7EmBfhujyTgjQzHmG6Nei6xxzYjQzpXmaSTHaBBRi2wATWWTLZPuupD+8/f58tqQRtzInhTodzCVTTK7kQbXgPJy+AcozrOeGN88lgyW6ewwX99cBqELvUJ/n/ONETUUZE8K9DuYziY5X+3iMgilBYqxLAAn1PUeONPZJOeKfgDuSv2ZpzaUpU5UqRvZkwL9DqazSb5W8k/UbrTISgsU/PXdNFlq8Exlk5u3iOxW/VmP+7Ni1aKXPSjQ72AqO8zXys0WWRdyrMV5FlyGiXSCZFyTpQbNdHaYJZpLXXfhYmxxnjV/QTyl/mQvCvQ7mM4mWWj4KyqH3fVuNKC8yKX6iE7SATWVTVIjxkYi27XU37JlSUQjjKcS4e9fBooC/Q6ms0mW8NYRCX1N8coyuAYXqynlVwfUCX/Z4HIs17XUzULDayhEIposJbtToN/BdHaYKnE2YiPht8j8E//r5WHlVwfU5MgQEYPVaBda9M5BaYFLNfUIJRgF+h00T6ByLBd+jt4/8S9U0zpRB1QsGuHYaNKfdBdyjr6yDI0aF6paJ0mCUaDfQSYZI5WIshLNht/19ve36EZ1og6wqWySucZoF+qP1/D4ejmlhoIEokC/AzNjOptk0Y2G3/X2ewheoFeOflCdyCWZ2Uh5/9/Ohbfj5r0MGiOagyGBKNDvYjo7zOXGaPgXY/0/HItk1KIfYFOZYc5XUtDw1o4PjV9/FtyoWvQSiAL9LqaySWar6fBbZMUFqtE0VeI6UQfYdDbJbHNhszCv82ym/tRQkGAU6HdxIpvkfHUY6utQXQtvx6V5VqNZxjVZaqBN55Kb9wQONdBv9giV+pNgFOh3MZUd3rxVW6gX1EoLFMgwpRs6D7TNazwQcv1ZpBpJUo8mmUhrspTsTYF+F9PZ5JVAH3LXe04jbgbeVHb4SqAP84J+cZ61SJbjGU2WkmAU6HcxlU2ytHmihtn1XmB2Q2PoB92x0SEWrTupmyVTfl6CU6DfxYnsMAuE3PV2DlecZ6Y2womc8quDLB6NkBnNULVkuKmb4jxzDeXnJTgF+l1khmOUYt5SsKF1vatFrL7OkhtVjv4ImMoOsxLJhNqid36PUC16CSpQoDezO8zsy2Z2zswe2ub9283sOTOrmdk9W977TTM7a2Yvmdnv2iG6Xb2Zkc3k2LB4eC2yq0ZM6EQddNMZ/zpPqC36BeYaGkMvwe0Z6M0sCjwK3AmcAu4zs1NbNnsNuB/4yJbPvgv4DuCtwDcDtwLf3XGpe2gqN8yKhbheiT/5asFldKIeAVPZJJfrI+G16KslrFbSGHppS5AW/W3AOefcK865KvAx4O7WDZxzrzrnXgAaWz7rgCSQAIaAOHCp41L30HRziGVYqRt/P0ta/uBIOJFLMtcYodGVHqHqjwQTJNBfB5xveX7Bf21PzrnPAJ8CZvyfp5xzL23dzsweMLMzZnZmbm4uyK57Zjqb5FJ9BBfaieq17DaS4wwnNFlq0G0OsQy5/mhBPGlHVy/GmtmbgW8ETuL9cfheM/uurds55x53zp12zp2enJzsZpHaNpVNsuBGqa+F9AfIP+ETmWPh7E8ONG/SVIZIrQQb5c536Kf+li3LxIjuNSzBBAn0F4HrW56f9F8L4n3AZ51za865NeCTwDvbK2J/Tftj6S2sHH1png1iZLNj4exPDrSpTJKFMJdB8FM3kXSeqCZLSUBBAv2zwM1mdqOZJYB7gScC7v814LvNLGZmcbwLsdekbg6yZo4+urEKtfXOd1hcYIkM02OpzvclB97xTPLKTcLDSN/4+0hmD1bPVw62PQO9c64GPAg8hRekP+GcO2tmj5jZXQBmdquZXQDeDzxmZmf9j/8p8FXgi8AXgC845/5LF/4dXTOdDXdhqnpxnvnGKNMaQ38kJGIR6sm89ySMC/qlBWpEGc3lO9+XHBmxIBs5554Entzy2sMtj5/FS+ls/Vwd+EcdlrGvcqk4K5Gs96Q4D5kTHe2vtjqndcSPmHhmEpYI5b4GrjjvXYjVrGppg2bG7sHMiKQnvCchtOhdcd6/4YhO1KMi2bzwHkL92dhsKKj+SHAK9AHER8M7UaPlBb9Fphb9UTE2nqfmIqGkbmqrl1lyo5xQj1DaoEAfQCrnB/pOL6bVqsRrayxqnZsj5XguxRKjVFcud7wvV1pkEc2qlvYo0AeQGZ+k7oxGscOx9H6PoBTPkR4KdHlEBkDzvgZhBPpYZYEFzaqWNinQBzA1NsIyI1QKnQZ6v0eQ0oiJo2Tanx1bX+sw9VffYGhjhSUyTI5qspQEp0AfwHTGm93YcYvMT/3ERhXojxJviO4o1uk1Hn/SXi05rslS0hYF+gCm/BO10ekyCP6Jnsxq+YOj5FhmiEWXIb7e4ezq5h+K1ETnhZIjRYE+gGaONVLu7ETd8P9QpMemwyiWHBJDsSiVeI7hWgHqtf3vqNTsEaqhIO1RoA9gPJ2gYBni60sd7ae0dImGM8byOlGPmnrzukx5/3WouYLqcE71R9qjQB+AmVEdGvNaZI2tS+4HV1m+xDJppnLpEEsnh8GVSXf7H6JbXvZu5TAydjyMIskRokAfUGN4ggiNjlpktbV53RnoiNpclrqDuRjFJW8wwFh+KowiyRGiQB9QNN35wlRWWmCBjKavH0HNdEulsP+RW+srl1l2aY6PjYZVLDkiFOgDGvJHyjTW9h/oY5VFViIZRjRZ6sjJTngX4FeXZve9j/rqHAsuwwktnyFtUqAPKOXnRTs5UZPVJaoJ3XDkKBqf9NItpaX9t+itNM8So0zqzlLSJgX6gDLNFtnCPgN9o0G6sUItqTHQR9HU2CgFl+po0l1sfYliNEcsqtNW2qMaE9DEpBfomyMf2lZZJkoD0/IHR9LxjDcXw3Uw6S61scz6kHqE0j4F+oCmJrKsumE2VveXo2+25OIZ3QLuKErGo6xEskQq+5x05xwjjQKNYfUIpX0K9AGNpxIsMYrb5wqWS/MzgCa7HGWVeI7EPifducoyMepE0uoRSvsU6AOKRIzVaI7oPpdBWPFz+6PjGgN9VG0MjZOuLe/rs2uLXsowPqoeobRPgb4NlXiOoer+WmSlJe9EHZ/UOjdHlUtNkHEFcK7tzy7OeT3ClGbFyj4o0LehlhwnVV/e12fXC16gzx/v7ObicnhFRiaJU6e8utz2Z1cWvECfmVCPUNoXKNCb2R1m9mUzO2dmD23z/u1m9pyZ1czsnpbX321mz7f8VMzsh0Isf0+51AS5xgqNevvr3dSLCxRdktERzWo8qpJZL+0yd+lC258tLfvLH6hHKPuwZ6A3syjwKHAncAq4z8xObdnsNeB+4COtLzrnPuWce5tz7m3A9wIl4OnOi90f0ZFJhmyDpUL76ZtIaYGVSLYLpZLDopl2WfYvzLejOWpr4ph6hNK+IC3624BzzrlXnHNV4GPA3a0bOOdedc69AOzW1L0H+KRzrrTv0vZZ84Yh85cutv3ZxPoipXgu5BLJYZKb8IL02mL7k+7c2hxlhognR8IulhwBQQL9dcD5lucX/NfadS/w0e3eMLMHzOyMmZ2Zm+vwLk5dNOKPmFmab/9EHd5Yojo0HnaR5BAZ96/PlPexsFmkvKgeoexbTy7Gmtk08C3AU9u975x73Dl32jl3enLy4A4fy/rLwxbbXO9mo95g1K3QGFagP8qS/mS5jdX2GzPx6hIV9Qhln4IE+ovA9S3PT/qvteNHgD93zm20+bkDpdn1riy31yK7vFJhghUi6YP7R0x6IJGmwhBWbP8m4emNZfUIZd+CBPpngZvN7EYzS+ClYJ5o8zj3sUPa5jBp3iWo1uZSxZcXFkjaBgktf3DkFaPtL4OwWtkgRwGnm4LLPu0Z6J1zNeBBvLTLS8AnnHNnzewRM7sLwMxuNbMLwPuBx8zsbPPzZnYDXo/gf3eh/L01NMoGsbbvErRwuTnZRWOgj7pKYoxktb1AP1OoMM4q0RE1FGR/At0Bwzn3JPDkltcebnn8LF5KZ7vPvsr+Lt4ePGasxXLE19tskfnT1zMTmtV41NWS44wWL1HZqJOMRwN95tLCEm+xdYbUI5R90szYNq0nxklWl3BtTGNvLm2cyinQH3mpPBOsMluoBP5Ic9y96o/slwJ9m+rJMXKssFQKfl15Y9W7eGtaefDIi49OMmarzLQR6Ff9cfejE5oVK/ujQN8mS+cZZ5XXl8uBP7N5n1nddOTIS+aOMWIVLi0uB/5M2b/9oFaulP1SoG9TfPQY47bSVtc7Wl6kZjEY0jo3R13aXwah0MYyCBvNu1Jp1I3skwJ9m4Zzx8hYmUvLK4G2r9UbJDeWKMfHwKzLpZODbijjLaNRXGrjlpTNUV5pBXrZHwX6NjUviBUC3iR8bm2dMVaoabKLAPjXaSqF4LNjo5UF6kQhmetSoWTQKdC3KTLinailxWAtsteXK0zYiia7iMe/TlNfCza7em29xkitQCWhHqHsnwJ9u/wTdX0l2Ik6W6gwxirREV2IFSDl9eysFGwZhNlCmXFbpZ4c62apZMAp0LfL73o3Ai6DMFMoM2GrJLMaAy1AMkeDKMmNJSob9T03nylUGLcVjdiSjijQt6uZgiktBJo0dWlplYyVtM6NeCIRqkM5xlnl0sreI7dmlr3lD2IaWikdUKBv1/AYDiPjCiwHmDTVHF2hyVLSVE9OMB5w0tRMwbvGM+Tf9EZkPxTo2xWJUk3kmGAl0Im6eZMJXYwVn6UnAs/FuFxYJWdFomooSAcU6PehkfJaZLMre8+OrTVvMqETVXyJzLHADYXVJdUf6ZwC/T5E03nGbZXXl3c/UesNR6Tsj67QxTTxxUYnGY+sMVPYu6GweZMb9QilAwr0+xAfnWScvbvec6vr5Jw/g1YtMmlK5cmyxuxycc9NN8fbq/5IBxTo98HSefKRvS+mzfhjoB0GwxoHLb7UBBEcpeXdZ8cW12sMVZc3PyOyXwr0+5GaIMsalwq7t8hmCxXGWaE+lINIsJtMyBHgr1lT3WPS3exKhXFb9Z4o9ScdUKDfj3SeKA3WlnefNPW6P9lFQyvlKn7QttIi67WdJ03NLHs3lfc+o7WSZP8U6PfDP1GrK3O7TpqaLZTJR1Y318cRATbz7eO2wuWV9R0381J/fo8wGu9R4WQQKdDvh9/1TteWWSnXdtxsplDhWKSIKb8qrfz6MGG7D7GcLXipG9PyxNIhBfr98E/UcVthZpex9LPNdUqUupFWzfrD6q5DLGdWKhyPrhFR/ZEOBQr0ZnaHmX3ZzM6Z2UPbvH+7mT1nZjUzu2fLe28ws6fN7CUze9HMbgip7P2Tana9V5nZZSz97HKJkcaqLqTJ1aJxXDK7571jZ5bLTEbXVH+kY3sGejOLAo8CdwKngPvM7NSWzV4D7gc+ss0u/hD4kHPuG4HbgGDr+x5kzRwrO5+o9YajvLpIlLpa9HINS+U5Hl3ddS7GjL/Ete4sJZ2KBdjmNuCcc+4VADP7GHA38GJzA+fcq/57jdYP+n8QYs65Z/zt1sIpdp/FhnCJUfK1FWZ36HovrK2TdQXviXL0slVqgqlCcdfUzWyhzAgF1R/pWJDUzXXA+ZbnF/zXgngLsGxmf2ZmnzezD/k9hKuY2QNmdsbMzszNBb/FWj9ZapwTieKOLfoZfww9oBNVruVPutupRV+u1mmUC8RcTakb6Vi3L8bGgO8Cfgm4FbgJL8VzFefc4865086505OTh2Td7XSeY9HdAr13w5HmtiJXSU2QdSu8vkv9GTctnyHhCBLoLwLXtzw/6b8WxAXgeefcK865GvAXwC1tlfCgSuWZiKzs2PWeKVQY06xG2Uk6z0h9mfm1CtVa45q3vVnVqj8SjiCB/lngZjO70cwSwL3AEwH3/yyQM7NmM/17acntH2rpPNmGNw56u0lTs4UKxyLNE1WpG9kiNUHU1RhxZS6vXtuqnym0Ln+gWbHSmT0Dvd8SfxB4CngJ+IRz7qyZPWJmdwGY2a1mdgF4P/CYmZ31P1vHS9v8lZl9ETDg97vzT+mx1Djp+jKlao2VyrWTpl4vVDg5VILECMSTfSigHGipK7Njt0v/KXUjYQoy6gbn3JPAk1tee7jl8bN4KZ3tPvsM8NYOyngwpfLEGlVSrDNbqJAdvnqK+myhzHRsDZJqzcs29hiiO1OocDJRBIdSN9IxzYzdr3Rri+zaPP1MoUI+uqbWmGyvZXb1dkN0ZwsVrkuUIZ6CRKrXpZMBo0C/X34ra2KbG5A0Go5LKxXGWFF+Xrbn14sT8e1Hbs0UKkzF1lR/JBQK9PvVXJgqsnrNELn54jobdcdovaBut2zP7+m9IVnedhmNGX/lUwV6CYMC/X7509LfmCxf0/X2WviOZHVJ09dle4k0xIa9SXcrVwf6ykadpdKGdxtKpf4kBAr0++W31N8wVLqm6z1TqDDMOtHGulr0srN0nuPRtR0aCjCiHqGERIF+v4ZGIZrgRKJ0TY5+tlC5MitWXW/ZSWqccVvl8uo6G/Urk6aaDYfkxpLqj4RCgX6/zCA1wbHotcPjXi+UOR71129T11t2ksqTbRRwDi6vXrnT1EyhzBBVorWSUn8SCgX6TqTyjLHK2nqN1crG5suzhQo3pcub24hsK50nVVsGuCp9M1NovVes6o90ToG+E+kJMg1vKeLW9M1MocIbk5XNbUS2lcqTqC4BXNUrnC1UuD7pB371CCUECvSdSF1pkW09UU8miv42CvSyg9Q40Y0iQ1SvaSi8Oe0/V/2RECjQdyI1QWJ9EWBzdmyj4ZgtVDgeW4NIHIYy/SyhHGR+a/26RJHXl1sDfZk3JkveE6VuJAQK9J1I54lUV0lYbbNFv1iqUq03vFE36bx30VZkO34Qf/NIldmWm8zPFiqcSPiBXqk/CYECfSf8bvWb0uubXe/m7xwrao3J7vwW/U2p8mZDobJRZ6FY9XqEFoVkro8FlEGhQN8J/0S9eaSyeaI2f6dry1pHXHbnNxSuH7oyF+PyijfMcsL85Q/UI5QQKNB3wj9Rb0yWN3P0zd9D1SWNmJDdtSxsdmmlQq3e4HW//mQbBdUfCY0CfSf81MzJZPmqFn08akTLC0rdyO6SObAok9E1Gg7m1q6kAFO1ZY24kdAo0HfCb3FNx4usVmqsrde8C2mjMWxdC1LJHiIRSE14y1njNRKaDQb1CCVMCvSdGB4DjEn/3rCzhTKvL5d5y2jVe185etlLasJbzhqYWa4wUyiTScaIlBfUopfQKNB3IhKF4TFyzj9RCxVmVyrclGpOdlGLTPaQzpOqNWfHeinA6zIJKC+p/khoFOg7lc4z2vC73ssVf/mD0uZ7IrtKTRCtLJGMR5gtVJgtVHhzs0eo+iMhUaDvVCrv3WAEeHFmhWqtcWWyi1pkspd0HivOcyI7zMyK11C4ScsfSMgCBXozu8PMvmxm58zsoW3ev93MnjOzmpnds+W9upk97/88EVbBD4zUOJHyAvmRBJ9/zQv4x6Jai14CSk1AeYnpTJzXFkrMr61z/WZDQfVHwrFnoDezKPAocCdwCrjPzE5t2ew14H7gI9vsouyce5v/c1eH5T140nkozjOVTXL2dS+FM26rgOlirOwtlQccbxqp8tKMV39ONBfEU+pGQhKkRX8bcM4594pzrgp8DLi7dQPn3KvOuReAxnY7GGipPJQXmR4dotZwAN7SxcNj3sVakd34a9ncMFzerD/NUVxK/UlYggT664DzLc8v+K8FlTSzM2b2WTP7oe02MLMH/G3OzM3NtbHrAyCdB9fgplHvxiOxiJHcWFZrTIJpTroburKo2fjmbSjVI5Rw9OJi7Budc6eBHwN+x8zetHUD59zjzrnTzrnTk5OTPShSiPw8anOkzfFMkkhJY6AlIL+eTMfWNl8abRQgmYVovF+lkgETJNBfBK5veX7Sfy0Q59xF//crwP8C3t5G+Q4+/0Q9OeQF+qlsEorzCvQSjN/zm/DTNaNDMRKVRaVtJFRBAv2zwM1mdqOZJYB7gUCjZ8xszMyG/Md54DuAF/db2APJP1GPR70LaFPZJJQWlLqRYPwGQc55gV71R7phz0DvnKsBDwJPAS8Bn3DOnTWzR8zsLgAzu9XMLgDvBx4zs7P+x78ROGNmXwA+Bfwr59xgBXq/5ZX3W2QnMgnvRFWLTIKIxiGZZXhjkaFYhOncsOqPhC4WZCPn3JPAk1tee7jl8bN4KZ2tn/tr4Fs6LOPB5rfIsq7AG8bfwm3TUXB1pW4kuNQEVlrgthvHOf3GMfj8PJwYrAyn9FegQC+7iCchMUKsvMinf/ndMP+y97q63hJUypuL8Uc/8w5wDv6fUjcSLi2BEIbUhNfdhiu/1aKXoNJ5KHk3mWd9BRobSt1IqBTow5DOQ2nee1ycv/KaSBCpCdUf6SoF+jCkJq6coM0TVi16CapZf5xTj1C6QoE+DKn8lRO0GfDV9Zag0nkvXbO+0lJ/FOglPAr0YUj7OXrnvFxrYsS7SCsSRLNRUFq40mBQ6kZCpEAfhlQeahWoFr3UjVpj0o5mUC8utKT+FOglPAr0YWgG9tK8lj+Q9jUXL2vWn9gwJFL9LZMMFAX6MGxtkanbLe1ott6L81r+QLpCgT4MV+VYtSCVtCm9JUevHqGETIE+DOktqZu0TlRpQyLtpWs2648aChIuBfowNFtgy+ehVlaLTNqXmriS+lP9kZAp0IdhKAOROMz9nfdcqRtpV9qfHVvUypUSPgX6MJh53e35r3jP1fWWdqXyULgIG0Wl/iR0CvRhSeWvrFypFpm0K52HhXPeY9UfCZkCfVhS41Bfv/JYpB2piZb6oxa9hEuBPiyt6RqlbqRdrcFd9UdCpkAflmZ3OxL3Ls6KtKM1uCt1IyFToA9L80RNTXgXZ0Xa0dqiV+pPQqZAH5bmyalut+xHsxVvUUjm+loUGTwK9GFJtbToRdrV2iOM6LSUcAWqUWZ2h5l92czOmdlD27x/u5k9Z2Y1M7tnm/czZnbBzP5tGIU+kJonqlr0sh/NBoLqj3TBnoHezKLAo8CdwCngPjM7tWWz14D7gY/ssJtfAz69/2IeAmrRSyeSOS9to/ojXRCkRX8bcM4594pzrgp8DLi7dQPn3KvOuReAxtYPm9m3AceBp0Mo78HVPEE1YkL2IxLxrvMo0EsXxAJscx1wvuX5BeAdQXZuZhHgt4CfAN6zy3YPAA8AvOENbwiy64MnnYd3/wv45h/ud0nksPq+h2H8pn6XQgZQkEDfiZ8DnnTOXbBdhhw65x4HHgc4ffq063KZusMMvvuf97sUcpjd8pP9LoEMqCCB/iJwfcvzk/5rQbwT+C4z+zlgBEiY2Zpz7poLuiIi0h1BAv2zwM1mdiNegL8X+LEgO3fO/XjzsZndD5xWkBcR6a09L8Y652rAg8BTwEvAJ5xzZ83sETO7C8DMbjWzC8D7gcfM7Gw3Cy0iIsGZcwcrJX769Gl35syZfhdDRORQMbPPOedOb/eepuCJiAw4BXoRkQGnQC8iMuAU6EVEBtyBuxhrZnPA1zvYRR6YD6k43aDydUbl64zK15mDXL43Oucmt3vjwAX6TpnZmZ2uPB8EKl9nVL7OqHydOejl24lSNyIiA06BXkRkwA1ioH+83wXYg8rXGZWvMypfZw56+bY1cDl6ERG52iC26EVEpIUCvYjIgDuUgT7AzcqHzOzj/vt/Y2Y39LBs15vZp8zsRTM7a2b/bJttvsfMCmb2vP/zcK/K11KGV83si/7xr1lFzjy/63+HL5jZLT0s2ze0fDfPm9mKmf3Clm16+h2a2YfN7LKZfanltXEze8bMXvZ/j+3w2Q/427xsZh/oYfk+ZGZ/5////bmZ5Xb47K51oYvl+6CZXWz5P/yBHT676/nexfJ9vKVsr5rZ8zt8tuvfX8ecc4fqB4gCXwVuAhLAF4BTW7b5OeDf+4/vBT7ew/JNA7f4j0eBr2xTvu8B/mufv8dXgfwu7/8A8EnAgG8H/qaP/9+zeJNB+vYdArcDtwBfanntN4GH/McPAb+xzefGgVf832P+47Eele+9QMx//BvblS9IXehi+T4I/FKA//9dz/dulW/L+78FPNyv76/Tn8PYot/zZuX+8z/wH/8p8H22270MQ+Scm3HOPec/XsVbw/+6Xhw7ZHcDf+g8nwVyZjbdh3J8H/BV51wns6U75pz7NLC45eXWevYHwA9t89HvB55xzi0655aAZ4A7elE+59zTzrufBMBn8e4O1xc7fH9BBDnfO7Zb+fzY8SPAR8M+bq8cxkC/3c3KtwbSzW38il4AJnpSuhZ+yujtwN9s8/Y7zewLZvZJM/um3pYMAAc8bWaf82/OvlWQ77kX7mXnE6zf3+Fx59yM/3gWOL7NNgfle/xpvB7advaqC930oJ9a+vAOqa+D8P19F3DJOffyDu/38/sL5DAG+kPBzEaA/wz8gnNuZcvbz+GlIr4V+DfAX/S4eADf6Zy7BbgT+Hkzu70PZdiVmSWAu4A/2ebtg/AdbnJeH/5AjlU2s18BasAf77BJv+rC7wFvAt4GzOClRw6i+9i9NX/gz6XDGOiD3Kx8cxsziwFZYKEnpfOOGccL8n/snPuzre8751acc2v+4yeBuJnle1U+/7gX/d+XgT/H6yK36uSm8GG5E3jOOXdp6xsH4TsELjXTWf7vy9ts09fv0bx7Nf8g8OP+H6NrBKgLXeGcu+ScqzvnGsDv73Dcfn9/MeCHgY/vtE2/vr92HMZAv3mzcr/Fdy/wxJZtngCaoxvuAf7nTpU8bH4+7z8CLznnfnuHbaaa1wzM7Da8/4de/iFKm9lo8zHeRbsvbdnsCeAn/dE33w4UWtIUvbJjS6rf36GvtZ59APjLbbZ5CnivmY35qYn3+q91nZndAfwycJdzrrTDNkHqQrfK13rN5307HDfI+d5N7wH+zjl3Ybs3+/n9taXfV4P384M3IuQreFfjf8V/7RG8Cg2QxOvunwP+Friph2X7Trwu/AvA8/7PDwA/C/ysv82DwFm8EQSfBd7V4+/vJv/YX/DL0fwOW8towKP+d/xF4HSPy5jGC9zZltf69h3i/cGZATbw8sQ/g3fd56+Al4H/AYz7254G/kPLZ3/ar4vngJ/qYfnO4eW3m/WwORLtBPDkbnWhR+X7I79uvYAXvKe3ls9/fs353ovy+a//p2ada9m2599fpz9aAkFEZMAdxtSNiIi0QYFeRGTAKdCLiAw4BXoRkQGnQC8iMuAU6EVEBpwCvYjIgPv/GH/9nNvYLy8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 27.799422, Train accuracy: 0.230667, val accuracy: 0.232000\n",
      "Loss: 23.615874, Train accuracy: 0.263889, val accuracy: 0.260000\n",
      "Loss: 20.101335, Train accuracy: 0.315111, val accuracy: 0.317000\n",
      "Loss: 17.333555, Train accuracy: 0.340222, val accuracy: 0.339000\n",
      "Loss: 14.546261, Train accuracy: 0.380333, val accuracy: 0.377000\n",
      "Loss: 12.640159, Train accuracy: 0.409444, val accuracy: 0.410000\n",
      "Loss: 10.965826, Train accuracy: 0.444222, val accuracy: 0.444000\n",
      "Loss: 9.578260, Train accuracy: 0.469333, val accuracy: 0.461000\n",
      "Loss: 8.295159, Train accuracy: 0.496778, val accuracy: 0.483000\n",
      "Loss: 7.670142, Train accuracy: 0.521222, val accuracy: 0.502000\n",
      "Loss: 6.443297, Train accuracy: 0.531444, val accuracy: 0.514000\n",
      "Loss: 6.021781, Train accuracy: 0.553444, val accuracy: 0.544000\n",
      "Loss: 5.375733, Train accuracy: 0.572444, val accuracy: 0.557000\n",
      "Loss: 4.275300, Train accuracy: 0.581889, val accuracy: 0.563000\n",
      "Loss: 4.480167, Train accuracy: 0.592000, val accuracy: 0.568000\n",
      "Loss: 4.080146, Train accuracy: 0.587889, val accuracy: 0.570000\n",
      "Loss: 3.487889, Train accuracy: 0.603667, val accuracy: 0.576000\n",
      "Loss: 3.705507, Train accuracy: 0.599222, val accuracy: 0.586000\n",
      "Loss: 3.007714, Train accuracy: 0.613222, val accuracy: 0.595000\n",
      "Loss: 2.907643, Train accuracy: 0.620000, val accuracy: 0.599000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12d8013d0>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.902583, Train accuracy: 0.433000, val accuracy: 0.422000\n",
      "Loss: 3.063709, Train accuracy: 0.508222, val accuracy: 0.514000\n",
      "Loss: 1.589463, Train accuracy: 0.551778, val accuracy: 0.562000\n",
      "Loss: 1.756811, Train accuracy: 0.593111, val accuracy: 0.598000\n",
      "Loss: 1.806484, Train accuracy: 0.592333, val accuracy: 0.593000\n",
      "Loss: 1.941559, Train accuracy: 0.608556, val accuracy: 0.607000\n",
      "Loss: 1.757121, Train accuracy: 0.621778, val accuracy: 0.625000\n",
      "Loss: 2.195497, Train accuracy: 0.607778, val accuracy: 0.606000\n",
      "Loss: 1.648399, Train accuracy: 0.603556, val accuracy: 0.598000\n",
      "Loss: 1.538595, Train accuracy: 0.599667, val accuracy: 0.593000\n",
      "Loss: 1.652803, Train accuracy: 0.566556, val accuracy: 0.582000\n",
      "Loss: 1.670344, Train accuracy: 0.617111, val accuracy: 0.629000\n",
      "Loss: 1.774161, Train accuracy: 0.595222, val accuracy: 0.573000\n",
      "Loss: 2.144473, Train accuracy: 0.621000, val accuracy: 0.596000\n",
      "Loss: 2.020449, Train accuracy: 0.611444, val accuracy: 0.617000\n",
      "Loss: 2.031824, Train accuracy: 0.626556, val accuracy: 0.627000\n",
      "Loss: 2.114568, Train accuracy: 0.614667, val accuracy: 0.617000\n",
      "Loss: 1.484796, Train accuracy: 0.625111, val accuracy: 0.613000\n",
      "Loss: 1.878536, Train accuracy: 0.611333, val accuracy: 0.601000\n",
      "Loss: 1.507123, Train accuracy: 0.612333, val accuracy: 0.596000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12d843070>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 286.441466, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 253.528220, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 224.495420, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 198.788038, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 175.826637, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 155.998783, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 138.277906, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 122.829871, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 108.966910, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 96.480692, Train accuracy: 1.000000, val accuracy: 0.133333\n",
      "Loss: 85.721360, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 75.941007, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 67.602709, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 59.918860, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 53.311371, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 47.050273, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 41.903673, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 37.472506, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 33.361096, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 29.538979, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 26.677902, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 23.671323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 20.994475, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 18.873967, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 16.918962, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.006282, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.541831, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.988252, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.974668, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.715483, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.055275, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.071799, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.149404, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.671258, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.060967, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.334468, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 4.840107, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 4.351841, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 4.058728, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.954942, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.518721, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.152707, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 3.012516, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.780773, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.709188, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.473849, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.414473, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.290470, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.058144, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 2.191244, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.926090, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.983812, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.793890, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.709344, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.505198, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.487753, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.732273, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.639729, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.663113, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.393665, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.366639, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.384177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.531454, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.348458, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.388348, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.668859, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.392844, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.319275, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.352884, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.289912, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.433398, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.348370, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.377412, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.313429, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.387699, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.316387, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.563977, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263792, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.356110, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.242929, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.309359, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.514135, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.237247, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.382641, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.343755, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.301803, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262659, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.421968, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.326447, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.267712, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.356412, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.236660, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.256435, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196287, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.274720, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262352, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.231613, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.243966, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.257743, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.198492, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.350242, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.275792, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.393993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.203518, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.140937, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.420112, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.180766, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.263525, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.417552, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.288170, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.278895, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.341364, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262864, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.210188, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443517, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.293966, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.469317, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.278583, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.249735, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.241749, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.291242, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.314459, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.237014, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.225105, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.336322, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.371642, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.214814, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.198141, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.420992, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.348318, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.121500, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.374404, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.245677, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.383657, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.061984, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.156394, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.404506, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.300320, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.309675, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.161962, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.436438, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.248290, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.170004, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.339001, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.272351, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.336644, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.243501, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.297006, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.295298, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.315061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 287.733711, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 254.497799, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 225.244781, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 199.762041, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 177.100236, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 156.859730, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 139.178212, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 123.753575, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 109.365054, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 97.139846, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 86.095528, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 76.333072, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 67.822130, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 60.443911, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 53.750707, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 47.627952, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 42.655916, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 37.682541, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 33.666476, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 29.999982, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now training with the following parameters: lr = 0.1, reg = 0.01, lr_decay=0.999\n",
      "Loss: 2.195564, Train accuracy: 0.276000, val accuracy: 0.279000\n",
      "Loss: 1.916066, Train accuracy: 0.387000, val accuracy: 0.408000\n",
      "Loss: 1.918882, Train accuracy: 0.429889, val accuracy: 0.446000\n",
      "Loss: 1.997879, Train accuracy: 0.402667, val accuracy: 0.425000\n",
      "Loss: 2.144877, Train accuracy: 0.419222, val accuracy: 0.413000\n",
      "Loss: 1.966354, Train accuracy: 0.386444, val accuracy: 0.406000\n",
      "Loss: 2.299674, Train accuracy: 0.455000, val accuracy: 0.454000\n",
      "Loss: 2.109398, Train accuracy: 0.387556, val accuracy: 0.371000\n",
      "Loss: 1.978406, Train accuracy: 0.390778, val accuracy: 0.414000\n",
      "Loss: 2.000480, Train accuracy: 0.403444, val accuracy: 0.394000\n",
      "Loss: 1.933396, Train accuracy: 0.409778, val accuracy: 0.432000\n",
      "Loss: 1.924784, Train accuracy: 0.407333, val accuracy: 0.413000\n",
      "Loss: 2.163073, Train accuracy: 0.360111, val accuracy: 0.353000\n",
      "Loss: 2.084954, Train accuracy: 0.357889, val accuracy: 0.377000\n",
      "Loss: 1.909397, Train accuracy: 0.405333, val accuracy: 0.419000\n",
      "Loss: 2.365807, Train accuracy: 0.386667, val accuracy: 0.403000\n",
      "Loss: 1.895310, Train accuracy: 0.399667, val accuracy: 0.399000\n",
      "Loss: 2.100787, Train accuracy: 0.389778, val accuracy: 0.425000\n",
      "Loss: 1.862993, Train accuracy: 0.453222, val accuracy: 0.439000\n",
      "Loss: 1.886986, Train accuracy: 0.418444, val accuracy: 0.444000\n",
      "Loss: 2.187982, Train accuracy: 0.418778, val accuracy: 0.430000\n",
      "Loss: 2.034545, Train accuracy: 0.419667, val accuracy: 0.432000\n",
      "Loss: 2.073697, Train accuracy: 0.392556, val accuracy: 0.445000\n",
      "Loss: 2.150039, Train accuracy: 0.380111, val accuracy: 0.389000\n",
      "Loss: 2.079202, Train accuracy: 0.424111, val accuracy: 0.452000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.01, lr_decay=0.99\n",
      "Loss: 2.344295, Train accuracy: 0.288444, val accuracy: 0.302000\n",
      "Loss: 2.027540, Train accuracy: 0.467000, val accuracy: 0.455000\n",
      "Loss: 2.080792, Train accuracy: 0.390889, val accuracy: 0.402000\n",
      "Loss: 2.092095, Train accuracy: 0.407333, val accuracy: 0.399000\n",
      "Loss: 2.080050, Train accuracy: 0.458222, val accuracy: 0.485000\n",
      "Loss: 2.088075, Train accuracy: 0.456333, val accuracy: 0.487000\n",
      "Loss: 2.199564, Train accuracy: 0.398000, val accuracy: 0.405000\n",
      "Loss: 2.094667, Train accuracy: 0.440556, val accuracy: 0.457000\n",
      "Loss: 1.980204, Train accuracy: 0.430333, val accuracy: 0.455000\n",
      "Loss: 2.032213, Train accuracy: 0.450667, val accuracy: 0.457000\n",
      "Loss: 2.202643, Train accuracy: 0.423333, val accuracy: 0.416000\n",
      "Loss: 2.107438, Train accuracy: 0.421889, val accuracy: 0.412000\n",
      "Loss: 2.235539, Train accuracy: 0.418444, val accuracy: 0.427000\n",
      "Loss: 2.187992, Train accuracy: 0.439333, val accuracy: 0.447000\n",
      "Loss: 2.152573, Train accuracy: 0.416667, val accuracy: 0.421000\n",
      "Loss: 1.913810, Train accuracy: 0.512444, val accuracy: 0.511000\n",
      "Loss: 1.864607, Train accuracy: 0.397667, val accuracy: 0.408000\n",
      "Loss: 2.171052, Train accuracy: 0.404556, val accuracy: 0.408000\n",
      "Loss: 2.005311, Train accuracy: 0.438000, val accuracy: 0.428000\n",
      "Loss: 2.139486, Train accuracy: 0.460111, val accuracy: 0.457000\n",
      "Loss: 1.790512, Train accuracy: 0.457889, val accuracy: 0.466000\n",
      "Loss: 2.184686, Train accuracy: 0.423333, val accuracy: 0.427000\n",
      "Loss: 2.040290, Train accuracy: 0.479556, val accuracy: 0.506000\n",
      "Loss: 1.872340, Train accuracy: 0.438444, val accuracy: 0.443000\n",
      "Loss: 1.957642, Train accuracy: 0.429222, val accuracy: 0.453000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.01, lr_decay=0.999\n",
      "Loss: 1.958900, Train accuracy: 0.280444, val accuracy: 0.288000\n",
      "Loss: 2.124729, Train accuracy: 0.408222, val accuracy: 0.408000\n",
      "Loss: 2.097768, Train accuracy: 0.415333, val accuracy: 0.447000\n",
      "Loss: 1.746993, Train accuracy: 0.460556, val accuracy: 0.469000\n",
      "Loss: 2.083099, Train accuracy: 0.451333, val accuracy: 0.468000\n",
      "Loss: 2.320772, Train accuracy: 0.461000, val accuracy: 0.433000\n",
      "Loss: 2.139003, Train accuracy: 0.416333, val accuracy: 0.427000\n",
      "Loss: 1.956033, Train accuracy: 0.400889, val accuracy: 0.423000\n",
      "Loss: 2.150935, Train accuracy: 0.427889, val accuracy: 0.441000\n",
      "Loss: 2.210791, Train accuracy: 0.385667, val accuracy: 0.377000\n",
      "Loss: 2.074275, Train accuracy: 0.399556, val accuracy: 0.402000\n",
      "Loss: 1.854912, Train accuracy: 0.398444, val accuracy: 0.413000\n",
      "Loss: 2.046731, Train accuracy: 0.479556, val accuracy: 0.478000\n",
      "Loss: 2.038488, Train accuracy: 0.429333, val accuracy: 0.447000\n",
      "Loss: 1.949521, Train accuracy: 0.430333, val accuracy: 0.417000\n",
      "Loss: 2.173299, Train accuracy: 0.428444, val accuracy: 0.435000\n",
      "Loss: 2.054548, Train accuracy: 0.438889, val accuracy: 0.456000\n",
      "Loss: 2.082734, Train accuracy: 0.464000, val accuracy: 0.448000\n",
      "Loss: 1.974851, Train accuracy: 0.451000, val accuracy: 0.477000\n",
      "Loss: 2.199102, Train accuracy: 0.408889, val accuracy: 0.426000\n",
      "Loss: 1.889324, Train accuracy: 0.419667, val accuracy: 0.414000\n",
      "Loss: 2.187573, Train accuracy: 0.419333, val accuracy: 0.439000\n",
      "Loss: 2.042739, Train accuracy: 0.438556, val accuracy: 0.438000\n",
      "Loss: 2.286534, Train accuracy: 0.407889, val accuracy: 0.413000\n",
      "Loss: 1.960379, Train accuracy: 0.417556, val accuracy: 0.424000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.01, lr_decay=0.99\n",
      "Loss: 2.193008, Train accuracy: 0.258889, val accuracy: 0.268000\n",
      "Loss: 2.326181, Train accuracy: 0.360333, val accuracy: 0.385000\n",
      "Loss: 1.922759, Train accuracy: 0.494667, val accuracy: 0.476000\n",
      "Loss: 2.410717, Train accuracy: 0.410333, val accuracy: 0.424000\n",
      "Loss: 1.778523, Train accuracy: 0.436333, val accuracy: 0.436000\n",
      "Loss: 2.159049, Train accuracy: 0.421333, val accuracy: 0.422000\n",
      "Loss: 1.936747, Train accuracy: 0.429889, val accuracy: 0.446000\n",
      "Loss: 2.354577, Train accuracy: 0.411000, val accuracy: 0.455000\n",
      "Loss: 2.039728, Train accuracy: 0.457889, val accuracy: 0.460000\n",
      "Loss: 2.064215, Train accuracy: 0.445111, val accuracy: 0.446000\n",
      "Loss: 2.193625, Train accuracy: 0.406111, val accuracy: 0.432000\n",
      "Loss: 2.096873, Train accuracy: 0.440444, val accuracy: 0.448000\n",
      "Loss: 2.117457, Train accuracy: 0.478667, val accuracy: 0.489000\n",
      "Loss: 1.983021, Train accuracy: 0.442444, val accuracy: 0.439000\n",
      "Loss: 2.332846, Train accuracy: 0.442889, val accuracy: 0.443000\n",
      "Loss: 2.390611, Train accuracy: 0.412111, val accuracy: 0.441000\n",
      "Loss: 1.903542, Train accuracy: 0.445222, val accuracy: 0.454000\n",
      "Loss: 1.919458, Train accuracy: 0.439222, val accuracy: 0.429000\n",
      "Loss: 2.142400, Train accuracy: 0.466444, val accuracy: 0.481000\n",
      "Loss: 1.990339, Train accuracy: 0.442778, val accuracy: 0.444000\n",
      "Loss: 1.884090, Train accuracy: 0.460889, val accuracy: 0.492000\n",
      "Loss: 2.214699, Train accuracy: 0.395222, val accuracy: 0.417000\n",
      "Loss: 1.929088, Train accuracy: 0.418667, val accuracy: 0.435000\n",
      "Loss: 1.801169, Train accuracy: 0.408889, val accuracy: 0.396000\n",
      "Loss: 1.911369, Train accuracy: 0.433222, val accuracy: 0.459000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.001, lr_decay=0.999\n",
      "Loss: 1.938351, Train accuracy: 0.344000, val accuracy: 0.340000\n",
      "Loss: 2.115928, Train accuracy: 0.465222, val accuracy: 0.481000\n",
      "Loss: 1.790773, Train accuracy: 0.587889, val accuracy: 0.565000\n",
      "Loss: 1.647891, Train accuracy: 0.623111, val accuracy: 0.602000\n",
      "Loss: 1.725802, Train accuracy: 0.613778, val accuracy: 0.585000\n",
      "Loss: 1.765246, Train accuracy: 0.623889, val accuracy: 0.594000\n",
      "Loss: 1.339520, Train accuracy: 0.607111, val accuracy: 0.579000\n",
      "Loss: 1.665400, Train accuracy: 0.622111, val accuracy: 0.589000\n",
      "Loss: 1.711589, Train accuracy: 0.604333, val accuracy: 0.561000\n",
      "Loss: 1.544866, Train accuracy: 0.682111, val accuracy: 0.611000\n",
      "Loss: 1.369678, Train accuracy: 0.675000, val accuracy: 0.623000\n",
      "Loss: 1.435585, Train accuracy: 0.648556, val accuracy: 0.636000\n",
      "Loss: 1.283224, Train accuracy: 0.710222, val accuracy: 0.674000\n",
      "Loss: 1.669103, Train accuracy: 0.634667, val accuracy: 0.600000\n",
      "Loss: 1.503712, Train accuracy: 0.617444, val accuracy: 0.602000\n",
      "Loss: 1.893792, Train accuracy: 0.666889, val accuracy: 0.638000\n",
      "Loss: 1.920969, Train accuracy: 0.677444, val accuracy: 0.630000\n",
      "Loss: 1.393928, Train accuracy: 0.667556, val accuracy: 0.613000\n",
      "Loss: 1.447638, Train accuracy: 0.700000, val accuracy: 0.666000\n",
      "Loss: 2.150711, Train accuracy: 0.597000, val accuracy: 0.548000\n",
      "Loss: 1.595292, Train accuracy: 0.642778, val accuracy: 0.623000\n",
      "Loss: 2.507403, Train accuracy: 0.553000, val accuracy: 0.543000\n",
      "Loss: 1.528374, Train accuracy: 0.689444, val accuracy: 0.642000\n",
      "Loss: 1.270886, Train accuracy: 0.683556, val accuracy: 0.659000\n",
      "Loss: 1.432309, Train accuracy: 0.635778, val accuracy: 0.619000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.001, lr_decay=0.99\n",
      "Loss: 1.835579, Train accuracy: 0.350778, val accuracy: 0.339000\n",
      "Loss: 1.497620, Train accuracy: 0.519667, val accuracy: 0.530000\n",
      "Loss: 1.689225, Train accuracy: 0.621222, val accuracy: 0.596000\n",
      "Loss: 1.565642, Train accuracy: 0.576222, val accuracy: 0.565000\n",
      "Loss: 1.424115, Train accuracy: 0.626778, val accuracy: 0.593000\n",
      "Loss: 1.785735, Train accuracy: 0.652778, val accuracy: 0.634000\n",
      "Loss: 1.053738, Train accuracy: 0.653444, val accuracy: 0.623000\n",
      "Loss: 1.890683, Train accuracy: 0.588111, val accuracy: 0.574000\n",
      "Loss: 1.503711, Train accuracy: 0.655222, val accuracy: 0.617000\n",
      "Loss: 1.245685, Train accuracy: 0.630556, val accuracy: 0.594000\n",
      "Loss: 1.326421, Train accuracy: 0.688222, val accuracy: 0.637000\n",
      "Loss: 1.675942, Train accuracy: 0.665111, val accuracy: 0.629000\n",
      "Loss: 1.725249, Train accuracy: 0.664778, val accuracy: 0.654000\n",
      "Loss: 1.278596, Train accuracy: 0.689667, val accuracy: 0.661000\n",
      "Loss: 1.778404, Train accuracy: 0.691889, val accuracy: 0.656000\n",
      "Loss: 1.668092, Train accuracy: 0.694111, val accuracy: 0.659000\n",
      "Loss: 1.301518, Train accuracy: 0.700667, val accuracy: 0.676000\n",
      "Loss: 1.542025, Train accuracy: 0.663667, val accuracy: 0.629000\n",
      "Loss: 1.056444, Train accuracy: 0.739333, val accuracy: 0.693000\n",
      "Loss: 1.532393, Train accuracy: 0.701889, val accuracy: 0.645000\n",
      "Loss: 1.618930, Train accuracy: 0.651556, val accuracy: 0.617000\n",
      "Loss: 1.400653, Train accuracy: 0.698444, val accuracy: 0.658000\n",
      "Loss: 1.220534, Train accuracy: 0.714556, val accuracy: 0.666000\n",
      "Loss: 1.387876, Train accuracy: 0.671222, val accuracy: 0.640000\n",
      "Loss: 1.104276, Train accuracy: 0.709000, val accuracy: 0.659000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.001, lr_decay=0.999\n",
      "Loss: 1.807687, Train accuracy: 0.378333, val accuracy: 0.369000\n",
      "Loss: 1.801897, Train accuracy: 0.526889, val accuracy: 0.531000\n",
      "Loss: 1.403136, Train accuracy: 0.556000, val accuracy: 0.554000\n",
      "Loss: 1.444202, Train accuracy: 0.655222, val accuracy: 0.624000\n",
      "Loss: 2.018431, Train accuracy: 0.655333, val accuracy: 0.646000\n",
      "Loss: 1.620171, Train accuracy: 0.580333, val accuracy: 0.569000\n",
      "Loss: 2.212731, Train accuracy: 0.589444, val accuracy: 0.564000\n",
      "Loss: 1.285022, Train accuracy: 0.607111, val accuracy: 0.599000\n",
      "Loss: 1.678292, Train accuracy: 0.558667, val accuracy: 0.543000\n",
      "Loss: 1.555292, Train accuracy: 0.637000, val accuracy: 0.579000\n",
      "Loss: 1.702744, Train accuracy: 0.674222, val accuracy: 0.639000\n",
      "Loss: 1.939177, Train accuracy: 0.613667, val accuracy: 0.588000\n",
      "Loss: 1.667883, Train accuracy: 0.687000, val accuracy: 0.651000\n",
      "Loss: 1.272553, Train accuracy: 0.626111, val accuracy: 0.615000\n",
      "Loss: 1.634119, Train accuracy: 0.683889, val accuracy: 0.659000\n",
      "Loss: 1.824026, Train accuracy: 0.655778, val accuracy: 0.628000\n",
      "Loss: 1.500014, Train accuracy: 0.684889, val accuracy: 0.646000\n",
      "Loss: 1.797530, Train accuracy: 0.672000, val accuracy: 0.636000\n",
      "Loss: 1.774573, Train accuracy: 0.620889, val accuracy: 0.568000\n",
      "Loss: 1.951449, Train accuracy: 0.689556, val accuracy: 0.651000\n",
      "Loss: 1.791192, Train accuracy: 0.654889, val accuracy: 0.624000\n",
      "Loss: 1.451144, Train accuracy: 0.655889, val accuracy: 0.614000\n",
      "Loss: 2.089172, Train accuracy: 0.600556, val accuracy: 0.578000\n",
      "Loss: 1.709856, Train accuracy: 0.643667, val accuracy: 0.618000\n",
      "Loss: 1.734684, Train accuracy: 0.676333, val accuracy: 0.634000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.001, lr_decay=0.99\n",
      "Loss: 2.143193, Train accuracy: 0.325444, val accuracy: 0.327000\n",
      "Loss: 1.640920, Train accuracy: 0.498556, val accuracy: 0.498000\n",
      "Loss: 1.540911, Train accuracy: 0.564111, val accuracy: 0.529000\n",
      "Loss: 1.460032, Train accuracy: 0.604667, val accuracy: 0.599000\n",
      "Loss: 1.559908, Train accuracy: 0.633667, val accuracy: 0.620000\n",
      "Loss: 1.919951, Train accuracy: 0.610333, val accuracy: 0.580000\n",
      "Loss: 1.880057, Train accuracy: 0.658333, val accuracy: 0.628000\n",
      "Loss: 1.768421, Train accuracy: 0.656778, val accuracy: 0.609000\n",
      "Loss: 1.612389, Train accuracy: 0.637556, val accuracy: 0.611000\n",
      "Loss: 1.504494, Train accuracy: 0.614444, val accuracy: 0.596000\n",
      "Loss: 1.964780, Train accuracy: 0.679000, val accuracy: 0.638000\n",
      "Loss: 1.907863, Train accuracy: 0.664333, val accuracy: 0.608000\n",
      "Loss: 1.446569, Train accuracy: 0.664222, val accuracy: 0.636000\n",
      "Loss: 1.759317, Train accuracy: 0.683444, val accuracy: 0.638000\n",
      "Loss: 1.843868, Train accuracy: 0.640333, val accuracy: 0.613000\n",
      "Loss: 1.674266, Train accuracy: 0.643556, val accuracy: 0.602000\n",
      "Loss: 1.877170, Train accuracy: 0.673111, val accuracy: 0.638000\n",
      "Loss: 1.211715, Train accuracy: 0.693333, val accuracy: 0.643000\n",
      "Loss: 1.561309, Train accuracy: 0.703000, val accuracy: 0.654000\n",
      "Loss: 1.533917, Train accuracy: 0.729222, val accuracy: 0.698000\n",
      "Loss: 1.569838, Train accuracy: 0.636000, val accuracy: 0.597000\n",
      "Loss: 1.568965, Train accuracy: 0.696778, val accuracy: 0.646000\n",
      "Loss: 1.454793, Train accuracy: 0.707333, val accuracy: 0.665000\n",
      "Loss: 1.472857, Train accuracy: 0.672778, val accuracy: 0.633000\n",
      "Loss: 2.124468, Train accuracy: 0.693889, val accuracy: 0.637000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.0001, lr_decay=0.999\n",
      "Loss: 1.869501, Train accuracy: 0.334667, val accuracy: 0.351000\n",
      "Loss: 1.359335, Train accuracy: 0.526000, val accuracy: 0.520000\n",
      "Loss: 1.170555, Train accuracy: 0.606333, val accuracy: 0.588000\n",
      "Loss: 1.719900, Train accuracy: 0.575111, val accuracy: 0.550000\n",
      "Loss: 1.177749, Train accuracy: 0.639778, val accuracy: 0.571000\n",
      "Loss: 1.570350, Train accuracy: 0.660111, val accuracy: 0.629000\n",
      "Loss: 1.110566, Train accuracy: 0.704000, val accuracy: 0.661000\n",
      "Loss: 1.086555, Train accuracy: 0.709667, val accuracy: 0.644000\n",
      "Loss: 1.740647, Train accuracy: 0.686667, val accuracy: 0.636000\n",
      "Loss: 1.300194, Train accuracy: 0.702556, val accuracy: 0.607000\n",
      "Loss: 0.700647, Train accuracy: 0.731667, val accuracy: 0.670000\n",
      "Loss: 1.236477, Train accuracy: 0.707444, val accuracy: 0.619000\n",
      "Loss: 1.051454, Train accuracy: 0.752667, val accuracy: 0.666000\n",
      "Loss: 0.948390, Train accuracy: 0.771444, val accuracy: 0.680000\n",
      "Loss: 0.924020, Train accuracy: 0.748556, val accuracy: 0.664000\n",
      "Loss: 0.880661, Train accuracy: 0.795000, val accuracy: 0.722000\n",
      "Loss: 0.889599, Train accuracy: 0.787778, val accuracy: 0.691000\n",
      "Loss: 0.911042, Train accuracy: 0.752556, val accuracy: 0.657000\n",
      "Loss: 1.024373, Train accuracy: 0.765111, val accuracy: 0.656000\n",
      "Loss: 0.891248, Train accuracy: 0.764778, val accuracy: 0.668000\n",
      "Loss: 1.339156, Train accuracy: 0.755222, val accuracy: 0.662000\n",
      "Loss: 0.959918, Train accuracy: 0.790222, val accuracy: 0.702000\n",
      "Loss: 0.996625, Train accuracy: 0.766000, val accuracy: 0.672000\n",
      "Loss: 0.782015, Train accuracy: 0.803111, val accuracy: 0.697000\n",
      "Loss: 0.903369, Train accuracy: 0.805444, val accuracy: 0.696000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.0001, lr_decay=0.99\n",
      "Loss: 2.105919, Train accuracy: 0.389889, val accuracy: 0.394000\n",
      "Loss: 1.889203, Train accuracy: 0.483778, val accuracy: 0.503000\n",
      "Loss: 1.146012, Train accuracy: 0.594111, val accuracy: 0.580000\n",
      "Loss: 1.385294, Train accuracy: 0.617667, val accuracy: 0.615000\n",
      "Loss: 1.352113, Train accuracy: 0.643667, val accuracy: 0.597000\n",
      "Loss: 1.287919, Train accuracy: 0.660667, val accuracy: 0.622000\n",
      "Loss: 1.471307, Train accuracy: 0.715222, val accuracy: 0.644000\n",
      "Loss: 0.916431, Train accuracy: 0.699444, val accuracy: 0.640000\n",
      "Loss: 1.354093, Train accuracy: 0.688333, val accuracy: 0.614000\n",
      "Loss: 0.793931, Train accuracy: 0.738667, val accuracy: 0.661000\n",
      "Loss: 1.379569, Train accuracy: 0.742333, val accuracy: 0.684000\n",
      "Loss: 1.076637, Train accuracy: 0.755111, val accuracy: 0.678000\n",
      "Loss: 0.738534, Train accuracy: 0.732111, val accuracy: 0.639000\n",
      "Loss: 1.056258, Train accuracy: 0.749667, val accuracy: 0.683000\n",
      "Loss: 1.251383, Train accuracy: 0.746000, val accuracy: 0.664000\n",
      "Loss: 1.721663, Train accuracy: 0.763889, val accuracy: 0.693000\n",
      "Loss: 0.892753, Train accuracy: 0.797333, val accuracy: 0.715000\n",
      "Loss: 1.048858, Train accuracy: 0.812667, val accuracy: 0.692000\n",
      "Loss: 0.889421, Train accuracy: 0.771000, val accuracy: 0.680000\n",
      "Loss: 1.147402, Train accuracy: 0.783222, val accuracy: 0.691000\n",
      "Loss: 0.711668, Train accuracy: 0.792333, val accuracy: 0.704000\n",
      "Loss: 1.188743, Train accuracy: 0.815444, val accuracy: 0.688000\n",
      "Loss: 1.267210, Train accuracy: 0.782778, val accuracy: 0.685000\n",
      "Loss: 0.731579, Train accuracy: 0.775667, val accuracy: 0.679000\n",
      "Loss: 1.479710, Train accuracy: 0.806778, val accuracy: 0.696000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.0001, lr_decay=0.999\n",
      "Loss: 1.781857, Train accuracy: 0.405222, val accuracy: 0.407000\n",
      "Loss: 2.274312, Train accuracy: 0.493778, val accuracy: 0.474000\n",
      "Loss: 1.483287, Train accuracy: 0.564000, val accuracy: 0.559000\n",
      "Loss: 1.339603, Train accuracy: 0.657444, val accuracy: 0.632000\n",
      "Loss: 1.087182, Train accuracy: 0.633333, val accuracy: 0.600000\n",
      "Loss: 1.689398, Train accuracy: 0.633889, val accuracy: 0.599000\n",
      "Loss: 1.622865, Train accuracy: 0.707333, val accuracy: 0.677000\n",
      "Loss: 1.316918, Train accuracy: 0.691333, val accuracy: 0.638000\n",
      "Loss: 0.925525, Train accuracy: 0.709000, val accuracy: 0.636000\n",
      "Loss: 1.520069, Train accuracy: 0.729111, val accuracy: 0.658000\n",
      "Loss: 1.095944, Train accuracy: 0.726444, val accuracy: 0.643000\n",
      "Loss: 1.482557, Train accuracy: 0.744778, val accuracy: 0.670000\n",
      "Loss: 1.048966, Train accuracy: 0.732778, val accuracy: 0.661000\n",
      "Loss: 1.220200, Train accuracy: 0.737444, val accuracy: 0.676000\n",
      "Loss: 1.492778, Train accuracy: 0.724111, val accuracy: 0.633000\n",
      "Loss: 1.208739, Train accuracy: 0.741222, val accuracy: 0.641000\n",
      "Loss: 0.775090, Train accuracy: 0.761556, val accuracy: 0.670000\n",
      "Loss: 0.692729, Train accuracy: 0.786778, val accuracy: 0.698000\n",
      "Loss: 0.805350, Train accuracy: 0.761667, val accuracy: 0.680000\n",
      "Loss: 1.234054, Train accuracy: 0.744889, val accuracy: 0.658000\n",
      "Loss: 1.231337, Train accuracy: 0.761333, val accuracy: 0.666000\n",
      "Loss: 1.435321, Train accuracy: 0.769667, val accuracy: 0.662000\n",
      "Loss: 0.695240, Train accuracy: 0.785222, val accuracy: 0.672000\n",
      "Loss: 1.530437, Train accuracy: 0.735111, val accuracy: 0.629000\n",
      "Loss: 1.136858, Train accuracy: 0.777111, val accuracy: 0.674000\n",
      "Now training with the following parameters: lr = 0.1, reg = 0.0001, lr_decay=0.99\n",
      "Loss: 1.859893, Train accuracy: 0.296889, val accuracy: 0.319000\n",
      "Loss: 1.682381, Train accuracy: 0.498111, val accuracy: 0.510000\n",
      "Loss: 1.930022, Train accuracy: 0.611333, val accuracy: 0.583000\n",
      "Loss: 1.303691, Train accuracy: 0.627333, val accuracy: 0.615000\n",
      "Loss: 1.276552, Train accuracy: 0.665333, val accuracy: 0.625000\n",
      "Loss: 1.139472, Train accuracy: 0.684556, val accuracy: 0.652000\n",
      "Loss: 1.972854, Train accuracy: 0.704889, val accuracy: 0.658000\n",
      "Loss: 1.513599, Train accuracy: 0.660444, val accuracy: 0.617000\n",
      "Loss: 1.059410, Train accuracy: 0.722778, val accuracy: 0.668000\n",
      "Loss: 1.124676, Train accuracy: 0.739333, val accuracy: 0.685000\n",
      "Loss: 0.705938, Train accuracy: 0.757667, val accuracy: 0.683000\n",
      "Loss: 0.856333, Train accuracy: 0.757222, val accuracy: 0.680000\n",
      "Loss: 0.976158, Train accuracy: 0.763444, val accuracy: 0.660000\n",
      "Loss: 0.705676, Train accuracy: 0.776111, val accuracy: 0.693000\n",
      "Loss: 1.002384, Train accuracy: 0.804667, val accuracy: 0.703000\n",
      "Loss: 1.567912, Train accuracy: 0.758778, val accuracy: 0.667000\n",
      "Loss: 1.269151, Train accuracy: 0.797000, val accuracy: 0.678000\n",
      "Loss: 0.798238, Train accuracy: 0.770778, val accuracy: 0.667000\n",
      "Loss: 0.539086, Train accuracy: 0.803111, val accuracy: 0.695000\n",
      "Loss: 0.817128, Train accuracy: 0.786222, val accuracy: 0.691000\n",
      "Loss: 1.335434, Train accuracy: 0.805111, val accuracy: 0.696000\n",
      "Loss: 0.759393, Train accuracy: 0.780556, val accuracy: 0.679000\n",
      "Loss: 0.813857, Train accuracy: 0.814111, val accuracy: 0.691000\n",
      "Loss: 1.218140, Train accuracy: 0.799000, val accuracy: 0.692000\n",
      "Loss: 0.899450, Train accuracy: 0.810111, val accuracy: 0.713000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.01, lr_decay=0.999\n",
      "Loss: 2.241205, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195584, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214249, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.079019, Train accuracy: 0.227778, val accuracy: 0.229000\n",
      "Loss: 2.029086, Train accuracy: 0.272444, val accuracy: 0.271000\n",
      "Loss: 1.943324, Train accuracy: 0.291111, val accuracy: 0.292000\n",
      "Loss: 1.922719, Train accuracy: 0.346444, val accuracy: 0.344000\n",
      "Loss: 1.921910, Train accuracy: 0.387333, val accuracy: 0.369000\n",
      "Loss: 1.925989, Train accuracy: 0.426222, val accuracy: 0.429000\n",
      "Loss: 2.117163, Train accuracy: 0.467333, val accuracy: 0.472000\n",
      "Loss: 1.841498, Train accuracy: 0.493444, val accuracy: 0.497000\n",
      "Loss: 1.987740, Train accuracy: 0.541000, val accuracy: 0.549000\n",
      "Loss: 2.094751, Train accuracy: 0.547444, val accuracy: 0.543000\n",
      "Loss: 2.059160, Train accuracy: 0.567556, val accuracy: 0.557000\n",
      "Loss: 2.048452, Train accuracy: 0.575111, val accuracy: 0.574000\n",
      "Loss: 1.944653, Train accuracy: 0.597889, val accuracy: 0.582000\n",
      "Loss: 1.694993, Train accuracy: 0.604222, val accuracy: 0.601000\n",
      "Loss: 1.711330, Train accuracy: 0.613444, val accuracy: 0.615000\n",
      "Loss: 1.607664, Train accuracy: 0.606000, val accuracy: 0.602000\n",
      "Loss: 1.594542, Train accuracy: 0.616889, val accuracy: 0.620000\n",
      "Loss: 1.666483, Train accuracy: 0.622333, val accuracy: 0.606000\n",
      "Loss: 1.468337, Train accuracy: 0.636667, val accuracy: 0.624000\n",
      "Loss: 1.923131, Train accuracy: 0.611556, val accuracy: 0.611000\n",
      "Loss: 1.832646, Train accuracy: 0.639000, val accuracy: 0.617000\n",
      "Loss: 1.837495, Train accuracy: 0.630556, val accuracy: 0.627000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.01, lr_decay=0.99\n",
      "Loss: 2.311832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193329, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172517, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.148310, Train accuracy: 0.216778, val accuracy: 0.222000\n",
      "Loss: 2.039029, Train accuracy: 0.248778, val accuracy: 0.251000\n",
      "Loss: 2.256385, Train accuracy: 0.284778, val accuracy: 0.293000\n",
      "Loss: 2.064011, Train accuracy: 0.354556, val accuracy: 0.347000\n",
      "Loss: 1.844232, Train accuracy: 0.385667, val accuracy: 0.382000\n",
      "Loss: 1.703599, Train accuracy: 0.419111, val accuracy: 0.416000\n",
      "Loss: 1.886197, Train accuracy: 0.473111, val accuracy: 0.464000\n",
      "Loss: 1.892334, Train accuracy: 0.488333, val accuracy: 0.497000\n",
      "Loss: 1.731257, Train accuracy: 0.517222, val accuracy: 0.527000\n",
      "Loss: 1.839768, Train accuracy: 0.522111, val accuracy: 0.503000\n",
      "Loss: 1.816509, Train accuracy: 0.553111, val accuracy: 0.546000\n",
      "Loss: 1.812684, Train accuracy: 0.578333, val accuracy: 0.578000\n",
      "Loss: 1.578339, Train accuracy: 0.588333, val accuracy: 0.579000\n",
      "Loss: 1.826213, Train accuracy: 0.600556, val accuracy: 0.601000\n",
      "Loss: 1.822169, Train accuracy: 0.613111, val accuracy: 0.605000\n",
      "Loss: 1.851634, Train accuracy: 0.597222, val accuracy: 0.601000\n",
      "Loss: 1.808610, Train accuracy: 0.623778, val accuracy: 0.612000\n",
      "Loss: 1.698674, Train accuracy: 0.608778, val accuracy: 0.609000\n",
      "Loss: 1.637523, Train accuracy: 0.622000, val accuracy: 0.616000\n",
      "Loss: 1.701519, Train accuracy: 0.631444, val accuracy: 0.615000\n",
      "Loss: 1.886563, Train accuracy: 0.616111, val accuracy: 0.619000\n",
      "Loss: 1.535694, Train accuracy: 0.626444, val accuracy: 0.614000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.01, lr_decay=0.999\n",
      "Loss: 2.295965, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275940, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.200272, Train accuracy: 0.231556, val accuracy: 0.236000\n",
      "Loss: 2.079808, Train accuracy: 0.253778, val accuracy: 0.254000\n",
      "Loss: 2.084764, Train accuracy: 0.294444, val accuracy: 0.303000\n",
      "Loss: 1.800308, Train accuracy: 0.364333, val accuracy: 0.364000\n",
      "Loss: 1.772500, Train accuracy: 0.412889, val accuracy: 0.406000\n",
      "Loss: 1.969584, Train accuracy: 0.452778, val accuracy: 0.457000\n",
      "Loss: 1.813898, Train accuracy: 0.458778, val accuracy: 0.466000\n",
      "Loss: 2.097387, Train accuracy: 0.501111, val accuracy: 0.504000\n",
      "Loss: 1.748884, Train accuracy: 0.523000, val accuracy: 0.524000\n",
      "Loss: 1.935300, Train accuracy: 0.562556, val accuracy: 0.563000\n",
      "Loss: 1.650122, Train accuracy: 0.557222, val accuracy: 0.550000\n",
      "Loss: 1.824262, Train accuracy: 0.603667, val accuracy: 0.598000\n",
      "Loss: 1.796896, Train accuracy: 0.594111, val accuracy: 0.582000\n",
      "Loss: 1.628625, Train accuracy: 0.602778, val accuracy: 0.587000\n",
      "Loss: 1.883182, Train accuracy: 0.607111, val accuracy: 0.607000\n",
      "Loss: 1.817520, Train accuracy: 0.641556, val accuracy: 0.622000\n",
      "Loss: 2.000607, Train accuracy: 0.630222, val accuracy: 0.627000\n",
      "Loss: 1.698911, Train accuracy: 0.647444, val accuracy: 0.625000\n",
      "Loss: 1.931088, Train accuracy: 0.630444, val accuracy: 0.621000\n",
      "Loss: 1.990693, Train accuracy: 0.641889, val accuracy: 0.630000\n",
      "Loss: 1.787988, Train accuracy: 0.615889, val accuracy: 0.617000\n",
      "Loss: 1.789196, Train accuracy: 0.648778, val accuracy: 0.647000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.01, lr_decay=0.99\n",
      "Loss: 2.326970, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.225428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198843, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.115324, Train accuracy: 0.226111, val accuracy: 0.227000\n",
      "Loss: 2.237705, Train accuracy: 0.274778, val accuracy: 0.275000\n",
      "Loss: 2.261943, Train accuracy: 0.292000, val accuracy: 0.298000\n",
      "Loss: 1.885802, Train accuracy: 0.367111, val accuracy: 0.357000\n",
      "Loss: 2.069123, Train accuracy: 0.410444, val accuracy: 0.400000\n",
      "Loss: 1.997017, Train accuracy: 0.449111, val accuracy: 0.444000\n",
      "Loss: 1.747780, Train accuracy: 0.475000, val accuracy: 0.465000\n",
      "Loss: 1.732529, Train accuracy: 0.501667, val accuracy: 0.502000\n",
      "Loss: 1.822215, Train accuracy: 0.527333, val accuracy: 0.530000\n",
      "Loss: 1.943392, Train accuracy: 0.549000, val accuracy: 0.549000\n",
      "Loss: 1.711373, Train accuracy: 0.580333, val accuracy: 0.574000\n",
      "Loss: 1.733904, Train accuracy: 0.569222, val accuracy: 0.577000\n",
      "Loss: 1.848984, Train accuracy: 0.575000, val accuracy: 0.579000\n",
      "Loss: 1.816858, Train accuracy: 0.593333, val accuracy: 0.598000\n",
      "Loss: 1.752488, Train accuracy: 0.596111, val accuracy: 0.590000\n",
      "Loss: 1.760267, Train accuracy: 0.602000, val accuracy: 0.596000\n",
      "Loss: 1.735353, Train accuracy: 0.606333, val accuracy: 0.613000\n",
      "Loss: 1.864748, Train accuracy: 0.619000, val accuracy: 0.623000\n",
      "Loss: 1.823269, Train accuracy: 0.620778, val accuracy: 0.615000\n",
      "Loss: 1.868805, Train accuracy: 0.610667, val accuracy: 0.620000\n",
      "Loss: 1.825146, Train accuracy: 0.631333, val accuracy: 0.629000\n",
      "Loss: 1.710285, Train accuracy: 0.642667, val accuracy: 0.639000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.001, lr_decay=0.999\n",
      "Loss: 2.151829, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184627, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300578, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154430, Train accuracy: 0.271000, val accuracy: 0.269000\n",
      "Loss: 1.916590, Train accuracy: 0.298444, val accuracy: 0.301000\n",
      "Loss: 1.969889, Train accuracy: 0.397111, val accuracy: 0.394000\n",
      "Loss: 1.726684, Train accuracy: 0.467000, val accuracy: 0.445000\n",
      "Loss: 1.749979, Train accuracy: 0.531333, val accuracy: 0.530000\n",
      "Loss: 1.480814, Train accuracy: 0.572000, val accuracy: 0.574000\n",
      "Loss: 1.477772, Train accuracy: 0.608444, val accuracy: 0.595000\n",
      "Loss: 1.228704, Train accuracy: 0.633222, val accuracy: 0.617000\n",
      "Loss: 0.802606, Train accuracy: 0.661556, val accuracy: 0.649000\n",
      "Loss: 1.157644, Train accuracy: 0.683333, val accuracy: 0.663000\n",
      "Loss: 1.211678, Train accuracy: 0.694444, val accuracy: 0.666000\n",
      "Loss: 1.242029, Train accuracy: 0.699889, val accuracy: 0.675000\n",
      "Loss: 1.000607, Train accuracy: 0.717556, val accuracy: 0.693000\n",
      "Loss: 0.787459, Train accuracy: 0.713889, val accuracy: 0.683000\n",
      "Loss: 1.197626, Train accuracy: 0.722444, val accuracy: 0.694000\n",
      "Loss: 1.095956, Train accuracy: 0.739111, val accuracy: 0.693000\n",
      "Loss: 1.064814, Train accuracy: 0.746556, val accuracy: 0.710000\n",
      "Loss: 1.107769, Train accuracy: 0.745111, val accuracy: 0.707000\n",
      "Loss: 0.892727, Train accuracy: 0.765667, val accuracy: 0.716000\n",
      "Loss: 0.874073, Train accuracy: 0.761778, val accuracy: 0.719000\n",
      "Loss: 1.066234, Train accuracy: 0.780556, val accuracy: 0.735000\n",
      "Loss: 0.898395, Train accuracy: 0.777000, val accuracy: 0.726000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.001, lr_decay=0.99\n",
      "Loss: 2.250462, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209184, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178851, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190229, Train accuracy: 0.245889, val accuracy: 0.245000\n",
      "Loss: 2.084820, Train accuracy: 0.293111, val accuracy: 0.299000\n",
      "Loss: 1.708065, Train accuracy: 0.353778, val accuracy: 0.352000\n",
      "Loss: 1.457884, Train accuracy: 0.417333, val accuracy: 0.407000\n",
      "Loss: 1.461566, Train accuracy: 0.487111, val accuracy: 0.492000\n",
      "Loss: 1.634728, Train accuracy: 0.560333, val accuracy: 0.535000\n",
      "Loss: 1.366421, Train accuracy: 0.602667, val accuracy: 0.584000\n",
      "Loss: 0.969704, Train accuracy: 0.638333, val accuracy: 0.624000\n",
      "Loss: 1.115272, Train accuracy: 0.656222, val accuracy: 0.640000\n",
      "Loss: 1.012227, Train accuracy: 0.664556, val accuracy: 0.656000\n",
      "Loss: 1.230329, Train accuracy: 0.689111, val accuracy: 0.677000\n",
      "Loss: 1.027586, Train accuracy: 0.695444, val accuracy: 0.679000\n",
      "Loss: 1.293640, Train accuracy: 0.719333, val accuracy: 0.694000\n",
      "Loss: 1.243175, Train accuracy: 0.715000, val accuracy: 0.687000\n",
      "Loss: 1.161713, Train accuracy: 0.739444, val accuracy: 0.714000\n",
      "Loss: 0.946277, Train accuracy: 0.736778, val accuracy: 0.702000\n",
      "Loss: 0.932252, Train accuracy: 0.742444, val accuracy: 0.713000\n",
      "Loss: 1.376601, Train accuracy: 0.752778, val accuracy: 0.712000\n",
      "Loss: 1.188147, Train accuracy: 0.756333, val accuracy: 0.718000\n",
      "Loss: 1.099084, Train accuracy: 0.767778, val accuracy: 0.720000\n",
      "Loss: 0.920705, Train accuracy: 0.775667, val accuracy: 0.729000\n",
      "Loss: 1.245690, Train accuracy: 0.774000, val accuracy: 0.726000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.001, lr_decay=0.999\n",
      "Loss: 2.230788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218040, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.735506, Train accuracy: 0.270222, val accuracy: 0.271000\n",
      "Loss: 1.955983, Train accuracy: 0.327778, val accuracy: 0.337000\n",
      "Loss: 1.732560, Train accuracy: 0.408667, val accuracy: 0.397000\n",
      "Loss: 1.583354, Train accuracy: 0.477000, val accuracy: 0.468000\n",
      "Loss: 1.469415, Train accuracy: 0.540000, val accuracy: 0.524000\n",
      "Loss: 1.222668, Train accuracy: 0.605222, val accuracy: 0.597000\n",
      "Loss: 1.138557, Train accuracy: 0.630556, val accuracy: 0.618000\n",
      "Loss: 1.174276, Train accuracy: 0.656111, val accuracy: 0.649000\n",
      "Loss: 1.173729, Train accuracy: 0.675111, val accuracy: 0.666000\n",
      "Loss: 1.144055, Train accuracy: 0.682444, val accuracy: 0.662000\n",
      "Loss: 1.199638, Train accuracy: 0.709889, val accuracy: 0.701000\n",
      "Loss: 0.914205, Train accuracy: 0.715556, val accuracy: 0.698000\n",
      "Loss: 1.014471, Train accuracy: 0.721778, val accuracy: 0.701000\n",
      "Loss: 1.120278, Train accuracy: 0.734667, val accuracy: 0.720000\n",
      "Loss: 0.997876, Train accuracy: 0.738667, val accuracy: 0.713000\n",
      "Loss: 0.897147, Train accuracy: 0.733333, val accuracy: 0.711000\n",
      "Loss: 0.942854, Train accuracy: 0.761667, val accuracy: 0.726000\n",
      "Loss: 0.869023, Train accuracy: 0.764889, val accuracy: 0.715000\n",
      "Loss: 1.044293, Train accuracy: 0.762333, val accuracy: 0.724000\n",
      "Loss: 0.662050, Train accuracy: 0.770556, val accuracy: 0.732000\n",
      "Loss: 0.702811, Train accuracy: 0.761667, val accuracy: 0.727000\n",
      "Loss: 0.984874, Train accuracy: 0.784556, val accuracy: 0.743000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.001, lr_decay=0.99\n",
      "Loss: 2.223859, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293495, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153228, Train accuracy: 0.264556, val accuracy: 0.262000\n",
      "Loss: 1.777459, Train accuracy: 0.318667, val accuracy: 0.324000\n",
      "Loss: 1.854320, Train accuracy: 0.420889, val accuracy: 0.400000\n",
      "Loss: 1.576286, Train accuracy: 0.470111, val accuracy: 0.462000\n",
      "Loss: 1.453880, Train accuracy: 0.515000, val accuracy: 0.510000\n",
      "Loss: 1.575288, Train accuracy: 0.562556, val accuracy: 0.552000\n",
      "Loss: 0.952409, Train accuracy: 0.604778, val accuracy: 0.572000\n",
      "Loss: 1.592641, Train accuracy: 0.633444, val accuracy: 0.606000\n",
      "Loss: 1.147186, Train accuracy: 0.660778, val accuracy: 0.644000\n",
      "Loss: 1.196705, Train accuracy: 0.675111, val accuracy: 0.657000\n",
      "Loss: 1.033840, Train accuracy: 0.696444, val accuracy: 0.682000\n",
      "Loss: 1.166263, Train accuracy: 0.709111, val accuracy: 0.690000\n",
      "Loss: 1.187469, Train accuracy: 0.719000, val accuracy: 0.692000\n",
      "Loss: 1.002786, Train accuracy: 0.727333, val accuracy: 0.701000\n",
      "Loss: 0.986336, Train accuracy: 0.741667, val accuracy: 0.710000\n",
      "Loss: 0.846545, Train accuracy: 0.745778, val accuracy: 0.712000\n",
      "Loss: 1.015066, Train accuracy: 0.734111, val accuracy: 0.703000\n",
      "Loss: 1.092781, Train accuracy: 0.761222, val accuracy: 0.703000\n",
      "Loss: 1.039531, Train accuracy: 0.758000, val accuracy: 0.718000\n",
      "Loss: 0.990837, Train accuracy: 0.759111, val accuracy: 0.699000\n",
      "Loss: 1.039243, Train accuracy: 0.779222, val accuracy: 0.722000\n",
      "Loss: 1.232528, Train accuracy: 0.781667, val accuracy: 0.725000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.0001, lr_decay=0.999\n",
      "Loss: 2.236740, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.090090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.131707, Train accuracy: 0.262556, val accuracy: 0.264000\n",
      "Loss: 1.786810, Train accuracy: 0.321778, val accuracy: 0.328000\n",
      "Loss: 1.896689, Train accuracy: 0.395889, val accuracy: 0.400000\n",
      "Loss: 1.524651, Train accuracy: 0.490222, val accuracy: 0.478000\n",
      "Loss: 1.513429, Train accuracy: 0.542444, val accuracy: 0.533000\n",
      "Loss: 1.359092, Train accuracy: 0.586222, val accuracy: 0.573000\n",
      "Loss: 1.455768, Train accuracy: 0.621778, val accuracy: 0.615000\n",
      "Loss: 1.240425, Train accuracy: 0.649222, val accuracy: 0.655000\n",
      "Loss: 0.983983, Train accuracy: 0.662556, val accuracy: 0.663000\n",
      "Loss: 1.268769, Train accuracy: 0.691111, val accuracy: 0.681000\n",
      "Loss: 0.854713, Train accuracy: 0.689222, val accuracy: 0.685000\n",
      "Loss: 0.876076, Train accuracy: 0.705889, val accuracy: 0.687000\n",
      "Loss: 0.661733, Train accuracy: 0.727667, val accuracy: 0.701000\n",
      "Loss: 0.760315, Train accuracy: 0.727778, val accuracy: 0.710000\n",
      "Loss: 0.877140, Train accuracy: 0.748667, val accuracy: 0.711000\n",
      "Loss: 0.901400, Train accuracy: 0.753556, val accuracy: 0.704000\n",
      "Loss: 0.798613, Train accuracy: 0.759444, val accuracy: 0.714000\n",
      "Loss: 0.752886, Train accuracy: 0.774444, val accuracy: 0.730000\n",
      "Loss: 0.966355, Train accuracy: 0.771889, val accuracy: 0.727000\n",
      "Loss: 0.741284, Train accuracy: 0.778333, val accuracy: 0.717000\n",
      "Loss: 0.819630, Train accuracy: 0.791000, val accuracy: 0.726000\n",
      "Loss: 0.642835, Train accuracy: 0.797889, val accuracy: 0.731000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.0001, lr_decay=0.99\n",
      "Loss: 2.145323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.354404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224312, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.027653, Train accuracy: 0.260889, val accuracy: 0.256000\n",
      "Loss: 2.084393, Train accuracy: 0.293000, val accuracy: 0.299000\n",
      "Loss: 1.940510, Train accuracy: 0.375111, val accuracy: 0.378000\n",
      "Loss: 1.488129, Train accuracy: 0.448222, val accuracy: 0.439000\n",
      "Loss: 1.417230, Train accuracy: 0.498667, val accuracy: 0.505000\n",
      "Loss: 1.299317, Train accuracy: 0.563667, val accuracy: 0.554000\n",
      "Loss: 1.432581, Train accuracy: 0.610889, val accuracy: 0.593000\n",
      "Loss: 1.213322, Train accuracy: 0.654556, val accuracy: 0.634000\n",
      "Loss: 1.164877, Train accuracy: 0.668889, val accuracy: 0.652000\n",
      "Loss: 1.410401, Train accuracy: 0.687222, val accuracy: 0.664000\n",
      "Loss: 1.015407, Train accuracy: 0.701111, val accuracy: 0.689000\n",
      "Loss: 0.846590, Train accuracy: 0.714111, val accuracy: 0.680000\n",
      "Loss: 0.975049, Train accuracy: 0.722111, val accuracy: 0.695000\n",
      "Loss: 0.967727, Train accuracy: 0.729778, val accuracy: 0.698000\n",
      "Loss: 1.016401, Train accuracy: 0.732111, val accuracy: 0.705000\n",
      "Loss: 0.783250, Train accuracy: 0.745111, val accuracy: 0.711000\n",
      "Loss: 0.928181, Train accuracy: 0.750778, val accuracy: 0.720000\n",
      "Loss: 1.111302, Train accuracy: 0.772889, val accuracy: 0.710000\n",
      "Loss: 0.701006, Train accuracy: 0.775667, val accuracy: 0.714000\n",
      "Loss: 0.911151, Train accuracy: 0.779556, val accuracy: 0.721000\n",
      "Loss: 0.993279, Train accuracy: 0.781444, val accuracy: 0.722000\n",
      "Loss: 0.737637, Train accuracy: 0.790667, val accuracy: 0.732000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.0001, lr_decay=0.999\n",
      "Loss: 2.154212, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228007, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176674, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.155598, Train accuracy: 0.272333, val accuracy: 0.275000\n",
      "Loss: 2.010369, Train accuracy: 0.341333, val accuracy: 0.344000\n",
      "Loss: 1.621943, Train accuracy: 0.437444, val accuracy: 0.431000\n",
      "Loss: 1.729144, Train accuracy: 0.505778, val accuracy: 0.497000\n",
      "Loss: 1.367337, Train accuracy: 0.540444, val accuracy: 0.530000\n",
      "Loss: 1.312139, Train accuracy: 0.594889, val accuracy: 0.583000\n",
      "Loss: 0.851648, Train accuracy: 0.645000, val accuracy: 0.631000\n",
      "Loss: 1.444436, Train accuracy: 0.673222, val accuracy: 0.653000\n",
      "Loss: 1.095415, Train accuracy: 0.693000, val accuracy: 0.675000\n",
      "Loss: 1.167146, Train accuracy: 0.705778, val accuracy: 0.678000\n",
      "Loss: 0.628083, Train accuracy: 0.712778, val accuracy: 0.684000\n",
      "Loss: 0.913510, Train accuracy: 0.719000, val accuracy: 0.692000\n",
      "Loss: 0.925695, Train accuracy: 0.742444, val accuracy: 0.708000\n",
      "Loss: 0.724540, Train accuracy: 0.729000, val accuracy: 0.693000\n",
      "Loss: 1.027770, Train accuracy: 0.757556, val accuracy: 0.716000\n",
      "Loss: 1.140973, Train accuracy: 0.768444, val accuracy: 0.723000\n",
      "Loss: 0.580101, Train accuracy: 0.773000, val accuracy: 0.711000\n",
      "Loss: 0.805723, Train accuracy: 0.770111, val accuracy: 0.692000\n",
      "Loss: 0.725039, Train accuracy: 0.791556, val accuracy: 0.736000\n",
      "Loss: 0.900539, Train accuracy: 0.797333, val accuracy: 0.734000\n",
      "Loss: 0.753089, Train accuracy: 0.806889, val accuracy: 0.731000\n",
      "Loss: 0.472258, Train accuracy: 0.818333, val accuracy: 0.738000\n",
      "Now training with the following parameters: lr = 0.01, reg = 0.0001, lr_decay=0.99\n",
      "Loss: 2.289794, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203307, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233605, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265737, Train accuracy: 0.268778, val accuracy: 0.268000\n",
      "Loss: 2.122183, Train accuracy: 0.315333, val accuracy: 0.318000\n",
      "Loss: 1.726427, Train accuracy: 0.405333, val accuracy: 0.403000\n",
      "Loss: 1.773183, Train accuracy: 0.482111, val accuracy: 0.473000\n",
      "Loss: 1.213449, Train accuracy: 0.543111, val accuracy: 0.540000\n",
      "Loss: 1.178263, Train accuracy: 0.592778, val accuracy: 0.578000\n",
      "Loss: 1.297549, Train accuracy: 0.621556, val accuracy: 0.591000\n",
      "Loss: 1.229049, Train accuracy: 0.654889, val accuracy: 0.626000\n",
      "Loss: 0.906861, Train accuracy: 0.664556, val accuracy: 0.651000\n",
      "Loss: 0.958884, Train accuracy: 0.686889, val accuracy: 0.679000\n",
      "Loss: 0.991370, Train accuracy: 0.704333, val accuracy: 0.694000\n",
      "Loss: 0.912740, Train accuracy: 0.710111, val accuracy: 0.693000\n",
      "Loss: 0.976040, Train accuracy: 0.726333, val accuracy: 0.703000\n",
      "Loss: 0.807364, Train accuracy: 0.741444, val accuracy: 0.712000\n",
      "Loss: 0.838159, Train accuracy: 0.739889, val accuracy: 0.704000\n",
      "Loss: 0.734921, Train accuracy: 0.760889, val accuracy: 0.709000\n",
      "Loss: 0.724566, Train accuracy: 0.767000, val accuracy: 0.725000\n",
      "Loss: 0.869691, Train accuracy: 0.763778, val accuracy: 0.713000\n",
      "Loss: 0.760997, Train accuracy: 0.771889, val accuracy: 0.729000\n",
      "Loss: 0.616297, Train accuracy: 0.782222, val accuracy: 0.710000\n",
      "Loss: 0.838091, Train accuracy: 0.791111, val accuracy: 0.727000\n",
      "Loss: 0.740719, Train accuracy: 0.785889, val accuracy: 0.715000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-1, 1e-2]#, 1e-3]\n",
    "reg_strengths = [1e-2, 1e-3, 1e-4]\n",
    "learning_rate_decays = [0.999, 0.99]\n",
    "hidden_layer_sizes = [100, 128]\n",
    "num_epochs = 25\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "best_trainer = None\n",
    "\n",
    "best_loss_history = []\n",
    "best_train_history = []\n",
    "best_val_history = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strengths:\n",
    "        for hl_size in hidden_layer_sizes:\n",
    "            for lr_decay in learning_rate_decays:\n",
    "                print(f\"Now training with the following parameters: lr = {lr}, reg = {reg}, lr_decay={lr_decay}\")\n",
    "                model = TwoLayerNet(n_input = train_X.shape[1], \n",
    "                                    n_output = 10, \n",
    "                                    hidden_layer_size = hl_size, \n",
    "                                    reg = reg)\n",
    "                dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "                trainer = Trainer(model, \n",
    "                                  dataset, \n",
    "                                  MomentumSGD(), \n",
    "                                  learning_rate=lr, \n",
    "                                  learning_rate_decay=lr_decay, \n",
    "                                  num_epochs=num_epochs,\n",
    "                                  batch_size=batch_size)\n",
    "                loss_history, train_history, val_history = trainer.fit()\n",
    "                val_accuracy = val_history[-1]\n",
    "                if not best_val_accuracy or best_val_accuracy < val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    best_classifier = model\n",
    "                    best_trainer = trainer\n",
    "                    best_loss_history = loss_history\n",
    "                    best_train_history = train_history\n",
    "                    best_val_history = val_history\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "# print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation accuracy achieved: 0.743000\n"
     ]
    }
   ],
   "source": [
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12dae2d90>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(best_loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(best_train_history)\n",
    "plt.plot(best_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.697000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-venv",
   "language": "python",
   "name": "dl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
